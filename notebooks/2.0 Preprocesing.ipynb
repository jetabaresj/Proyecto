{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16113712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ace8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hourly_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Configurar índice temporal para la descomposición\n",
    "    df = df.copy()\n",
    "    df = df.set_index('Fecha').asfreq('h')\n",
    "    \n",
    "    # Interpolar valores faltantes\n",
    "    df['Volumen'] = df['Volumen'].interpolate()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65cfa574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(df: pd.DataFrame, fecha_col='Fecha') -> pd.DataFrame:\n",
    "    # Copia para no modificar el original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    if fecha_col not in df_result.columns:\n",
    "        df_result[fecha_col] = df_result.index\n",
    "    \n",
    "    # Características básicas de tiempo\n",
    "    df_result['hora'] = df_result[fecha_col].dt.hour\n",
    "    df_result['dia'] = df_result[fecha_col].dt.day\n",
    "    df_result['dia_semana'] = df_result[fecha_col].dt.dayofweek \n",
    "    df_result['dia_year'] = df_result[fecha_col].dt.dayofyear\n",
    "    df_result['semana_year'] = df_result[fecha_col].dt.isocalendar().week\n",
    "    df_result['mes'] = df_result[fecha_col].dt.month\n",
    "    df_result['trimestre'] = df_result[fecha_col].dt.quarter\n",
    "    df_result['year'] = df_result[fecha_col].dt.year\n",
    "    \n",
    "    # Características derivadas\n",
    "    df_result['fin_de_semana'] = df_result['dia_semana'].isin([5, 6]).astype(int)\n",
    "    df_result['dia_laboral'] = (~df_result['dia_semana'].isin([5, 6])).astype(int)\n",
    "    \n",
    "    # Parte del día (madrugada, mañana, tarde, noche)\n",
    "    df_result['parte_dia'] = pd.cut(\n",
    "        df_result['hora'], \n",
    "        bins=[-1, 5, 11, 17, 23], \n",
    "        labels=['madrugada', 'mañana', 'tarde', 'noche']\n",
    "    )\n",
    "    \n",
    "    # Festivos en Colombia\n",
    "    festivos_colombia = holidays.country_holidays('CO', years=df_result[fecha_col].dt.year.unique())\n",
    "    df_result['es_festivo'] = df_result[fecha_col].dt.date.astype('datetime64[ns]').isin(festivos_colombia).astype(int)\n",
    "        \n",
    "    # Características cíclicas (seno y coseno)\n",
    "    df_result['hora_seno'] = np.sin(2 * np.pi * df_result['hora'] / 24)\n",
    "    df_result['hora_coseno'] = np.cos(2 * np.pi * df_result['hora'] / 24)\n",
    "    df_result['dia_semana_seno'] = np.sin(2 * np.pi * df_result['dia_semana'] / 7)\n",
    "    df_result['dia_semana_coseno'] = np.cos(2 * np.pi * df_result['dia_semana'] / 7)\n",
    "    df_result['mes_seno'] = np.sin(2 * np.pi * df_result['mes'] / 12)\n",
    "    df_result['mes_coseno'] = np.cos(2 * np.pi * df_result['mes'] / 12)\n",
    "    \n",
    "    return df_result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4e7aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seasonal_features(df: pd.DataFrame, period=24, return_components=False):\n",
    "    # Crear copia para no modificar el original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    if 'Fecha' not in df_result.columns:\n",
    "        df_result['Fecha'] = df_result.index\n",
    "\n",
    "    # Verificar frecuencia horaria\n",
    "    if not isinstance(df_result.index, pd.DatetimeIndex):\n",
    "        df_result = df_result.set_index('Fecha').asfreq('h')\n",
    "    \n",
    "    # Realizar descomposición estacional\n",
    "    result = seasonal_decompose(df_result['Volumen'], model='additive', period=period)\n",
    "    \n",
    "    # Añadir componentes al DataFrame original\n",
    "    df_result['trend'] = result.trend.values\n",
    "    df_result['seasonal'] = result.seasonal.values\n",
    "    df_result['residual'] = result.resid.values\n",
    "    \n",
    "    # Calcular características adicionales\n",
    "    df_result['detrended'] = df_result['Volumen'] - df_result['trend']\n",
    "    df_result['seas_strength'] = abs(df_result['seasonal'] / df_result['Volumen'])\n",
    "    df_result['seas_norm'] = df_result['seasonal'] / df_result['seasonal'].std()\n",
    "    \n",
    "    if return_components:\n",
    "        return df_result, result\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10ff5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_features(df: pd.DataFrame, target_col='Volumen', windows=[1, 24, 48, 168]):\n",
    "    # Crear copia para no modificar el original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # Calcular estadísticas para cada ventana\n",
    "    for window in windows:\n",
    "        # Estadísticas móviles\n",
    "        df_result[f'rolling_mean_{window}h'] = df_result[target_col].rolling(window=window, min_periods=1).mean()\n",
    "        df_result[f'rolling_std_{window}h'] = df_result[target_col].rolling(window=window, min_periods=1).std()\n",
    "        df_result[f'rolling_min_{window}h'] = df_result[target_col].rolling(window=window, min_periods=1).min()\n",
    "        df_result[f'rolling_max_{window}h'] = df_result[target_col].rolling(window=window, min_periods=1).max()\n",
    "        \n",
    "        # Diferencias con respecto al promedio móvil\n",
    "        df_result[f'diff_from_mean_{window}h'] = df_result[target_col] - df_result[f'rolling_mean_{window}h']\n",
    "        df_result[f'pct_diff_from_mean_{window}h'] = (df_result[target_col] / df_result[f'rolling_mean_{window}h'] - 1) * 100\n",
    "        \n",
    "    # Patrones semanales (168 horas)\n",
    "    if 168 in windows:\n",
    "        df_result['diff_from_last_week'] = df_result[target_col].diff(168)\n",
    "        df_result['pct_diff_from_last_week'] = df_result[target_col].pct_change(168) * 100\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5614cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gas_law_features(df: pd.DataFrame, presion_col='Presion', temperatura_col='Temperatura', volumen_col='Volumen'):\n",
    "    # Crear copia para no modificar el original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    # Convertir temperatura a Kelvin\n",
    "    df_result['temperatura_K'] = df_result[temperatura_col] + 273.15\n",
    "    \n",
    "    # Leyes de los gases\n",
    "    df_result['PV_producto'] = df_result[presion_col] * df_result[volumen_col]\n",
    "    df_result['V_T_ratio'] = df_result[volumen_col] / df_result['temperatura_K']\n",
    "    df_result['P_T_ratio'] = df_result[presion_col] / df_result['temperatura_K']\n",
    "    df_result['PV_T_ratio'] = df_result['PV_producto'] / df_result['temperatura_K']\n",
    "    \n",
    "    # Calcular desviaciones\n",
    "    for col in ['PV_producto', 'V_T_ratio', 'P_T_ratio', 'PV_T_ratio']:\n",
    "        mean_val = df_result[col].mean()\n",
    "        df_result[f'{col}_deviation'] = ((df_result[col] - mean_val) / mean_val) * 100\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11cf9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df: pd.DataFrame, columns, method='zscore', threshold=3.0):\n",
    "    # Crear copia para no modificar el original\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        if col not in df_result.columns:\n",
    "            print(f\"Columna {col} no encontrada en el DataFrame\")\n",
    "            continue\n",
    "            \n",
    "        if method == 'zscore':\n",
    "            # Método Z-score\n",
    "            z_scores = stats.zscore(df_result[col], nan_policy='omit')\n",
    "            df_result[f'{col}_outlier_zscore'] = (abs(z_scores) > threshold).astype(int)\n",
    "            \n",
    "        elif method == 'iqr':\n",
    "            # Método IQR\n",
    "            Q1 = df_result[col].quantile(0.25)\n",
    "            Q3 = df_result[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            df_result[f'{col}_outlier_iqr'] = ((df_result[col] < lower_bound) | \n",
    "                                               (df_result[col] > upper_bound)).astype(int)\n",
    "    \n",
    "    # Columna agregada de outliers\n",
    "    outlier_cols = [col for col in df_result.columns if '_outlier_' in col]\n",
    "    if outlier_cols:\n",
    "        df_result['is_any_outlier'] = df_result[outlier_cols].max(axis=1)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2f69989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_for_anomaly_detection(df: pd.DataFrame, presion_col='Presion', \n",
    "                                          temperatura_col='Temperatura', volumen_col='Volumen'):\n",
    "    \"\"\"Función principal para crear todas las características para detección de anomalías\"\"\"\n",
    "    # 0. Preparar los datos\n",
    "    df_processed = prepare_hourly_data(df)\n",
    "    \n",
    "    # 1. Extraer características temporales\n",
    "    df_processed = extract_datetime_features(df_processed)\n",
    "    \n",
    "    # 2. Añadir características de estacionalidad\n",
    "    df_processed = extract_seasonal_features(df_processed)\n",
    "    \n",
    "    # 3. Calcular promedios móviles y estadísticas relacionadas\n",
    "    df_processed = calculate_rolling_features(df_processed, target_col=volumen_col)\n",
    "    \n",
    "    # 4. Añadir características basadas en leyes de los gases\n",
    "    df_processed = gas_law_features(df_processed, presion_col=presion_col, \n",
    "                                   temperatura_col=temperatura_col, volumen_col=volumen_col)\n",
    "    \n",
    "    # 5. Detectar outliers en columnas relevantes\n",
    "    columns_for_outlier_detection = [\n",
    "        volumen_col,\n",
    "        'diff_from_mean_24h',\n",
    "        'diff_from_mean_168h',\n",
    "        'PV_producto_deviation',\n",
    "        'V_T_ratio_deviation',\n",
    "        'P_T_ratio_deviation',\n",
    "        'residual'\n",
    "    ]\n",
    "    \n",
    "    # Detectar outliers con ambos métodos\n",
    "    df_processed = detect_outliers(df_processed, columns_for_outlier_detection, method='zscore')\n",
    "    df_processed = detect_outliers(df_processed, columns_for_outlier_detection, method='iqr')\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "864197eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código principal para procesar datos\n",
    "def process_gas_data(data: pd.DataFrame):\n",
    "    \"\"\"Procesa datos de gas por cliente para detección de anomalías\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for cliente, df_cliente in data.groupby('Cliente'):\n",
    "        print(f\"Procesando cliente: {cliente}\")\n",
    "        \n",
    "        # Aplicar todas las funciones de ingeniería de características\n",
    "        df_processed = create_features_for_anomaly_detection(df_cliente)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results[cliente] = df_processed\n",
    "        \n",
    "        # Mostrar resumen de outliers detectados\n",
    "        n_outliers = df_processed['is_any_outlier'].sum()\n",
    "        print(f\"Se detectaron {n_outliers} posibles anomalías para el cliente {cliente}\")\n",
    "        \n",
    "        # Opcional: guardar en CSV\n",
    "        df_processed.to_csv(f\"../data/processed/{cliente}_processed.csv\", index=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb35a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando cliente: CLIENTE1\n",
      "Se detectaron 2621 posibles anomalías para el cliente CLIENTE1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esteb\\AppData\\Local\\Temp\\ipykernel_29144\\1140426547.py:31: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_result['es_festivo'] = df_result[fecha_col].dt.date.astype('datetime64[ns]').isin(festivos_colombia).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando cliente: CLIENTE10\n",
      "Se detectaron 19062 posibles anomalías para el cliente CLIENTE10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esteb\\AppData\\Local\\Temp\\ipykernel_29144\\1140426547.py:31: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  df_result['es_festivo'] = df_result[fecha_col].dt.date.astype('datetime64[ns]').isin(festivos_colombia).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando cliente: CLIENTE11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m data = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/data.csv\u001b[39m\u001b[33m\"\u001b[39m, parse_dates=[\u001b[33m'\u001b[39m\u001b[33mFecha\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Procesar datos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results = \u001b[43mprocess_gas_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mprocess_gas_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcesando cliente: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcliente\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Aplicar todas las funciones de ingeniería de características\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_processed = \u001b[43mcreate_features_for_anomaly_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cliente\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Guardar resultados\u001b[39;00m\n\u001b[32m     13\u001b[39m results[cliente] = df_processed\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcreate_features_for_anomaly_detection\u001b[39m\u001b[34m(df, presion_col, temperatura_col, volumen_col)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Función principal para crear todas las características para detección de anomalías\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 0. Preparar los datos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_processed = \u001b[43mprepare_hourly_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1. Extraer características temporales\u001b[39;00m\n\u001b[32m      8\u001b[39m df_processed = extract_datetime_features(df_processed)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mprepare_hourly_data\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_hourly_data\u001b[39m(df: pd.DataFrame) -> pd.DataFrame:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Configurar índice temporal para la descomposición\u001b[39;00m\n\u001b[32m      3\u001b[39m     df = df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFecha\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Interpolar valores faltantes\u001b[39;00m\n\u001b[32m      7\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mVolumen\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mVolumen\u001b[39m\u001b[33m'\u001b[39m].interpolate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:9231\u001b[39m, in \u001b[36mNDFrame.asfreq\u001b[39m\u001b[34m(self, freq, method, how, normalize, fill_value)\u001b[39m\n\u001b[32m   9124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   9125\u001b[39m \u001b[33;03mConvert time series to specified frequency.\u001b[39;00m\n\u001b[32m   9126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   9227\u001b[39m \u001b[33;03m2000-01-01 00:03:00    3.0\u001b[39;00m\n\u001b[32m   9228\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   9229\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresample\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asfreq\n\u001b[32m-> \u001b[39m\u001b[32m9231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masfreq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\resample.py:2837\u001b[39m, in \u001b[36masfreq\u001b[39m\u001b[34m(obj, freq, method, how, normalize, fill_value)\u001b[39m\n\u001b[32m   2835\u001b[39m dti = date_range(obj.index.min(), obj.index.max(), freq=freq, unit=unit)\n\u001b[32m   2836\u001b[39m dti.name = obj.index.name\n\u001b[32m-> \u001b[39m\u001b[32m2837\u001b[39m new_obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m   2839\u001b[39m     new_obj.index = new_obj.index.normalize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5378\u001b[39m, in \u001b[36mDataFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5359\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5360\u001b[39m     NDFrame.reindex,\n\u001b[32m   5361\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5376\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5377\u001b[39m ) -> DataFrame:\n\u001b[32m-> \u001b[39m\u001b[32m5378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5382\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5607\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5609\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5610\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5612\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5630\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5632\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5633\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5637\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5638\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5639\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5640\u001b[39m     fill_value=fill_value,\n\u001b[32m   5641\u001b[39m     copy=copy,\n\u001b[32m   5642\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5643\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Esteb\\Desktop\\Universidad\\Proyecto\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot handle a non-unique multi-index!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_unique:\n\u001b[32m   4428\u001b[39m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4431\u001b[39m     indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n",
      "\u001b[31mValueError\u001b[39m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "data = pd.read_csv(\"../data/raw/data.csv\", parse_dates=['Fecha'])\n",
    "\n",
    "# Procesar datos\n",
    "results = process_gas_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
