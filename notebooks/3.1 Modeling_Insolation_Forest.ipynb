{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c8f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos de Detección de Outliers\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506fbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ISOLATION FOREST\n",
    "def detect_with_isolation_forest(data, contamination=0.025):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Preparar datos\n",
    "    df_iso = df.drop([\"Cliente\", \"Fecha\"], axis=1)\n",
    "    df_iso = df_iso.replace([np.inf, -np.inf], np.nan).ffill()\n",
    "    \n",
    "    # Escalar datos\n",
    "    scaler = RobustScaler()\n",
    "    X = scaler.fit_transform(df_iso)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    clf = IsolationForest(n_estimators=250, contamination=contamination, random_state=42)\n",
    "    df[\"anomaly\"] = clf.fit_predict(X)\n",
    "    df[\"anomaly\"] = df[\"anomaly\"].map({1: 0, -1: 1})  # Convertir a 0=normal, 1=anomalía\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60cecbc1-c4db-4b57-9fab-f149174e5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_isolation_forest(df, contamination=0.1):\n",
    "    # Eliminar filas con valores faltantes\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Suponiendo que las columnas numéricas son las que vamos a usar para el modelo\n",
    "    X = df.select_dtypes(include=[float, int])  # Ajusta según tus columnas\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    clf = IsolationForest(n_estimators=250, contamination=contamination, random_state=42)\n",
    "    df[\"anomaly\"] = clf.fit_predict(X)\n",
    "    \n",
    "    # Convertir a 0=normal, 1=anomalía\n",
    "    df[\"anomaly\"] = df[\"anomaly\"].map({1: 0, -1: 1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d082fcda-47b8-4768-ab45-aec549acdfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def detect_with_isolation_forest(df, contamination=0.1):\n",
    "    # Imputar valores NaN con la media\n",
    "    imputer = SimpleImputer(strategy='mean')  # Puedes cambiar 'mean' por 'median' si prefieres la mediana\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df.select_dtypes(include=[float, int])))\n",
    "    \n",
    "    # Mantener las columnas originales en el dataframe\n",
    "    df[df_imputed.columns] = df_imputed\n",
    "    \n",
    "    # Suponiendo que las columnas numéricas son las que vamos a usar para el modelo\n",
    "    X = df.select_dtypes(include=[float, int])  # Ajusta según tus columnas\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    clf = IsolationForest(n_estimators=250, contamination=contamination, random_state=42)\n",
    "    df[\"anomaly\"] = clf.fit_predict(X)\n",
    "    \n",
    "    # Convertir a 0=normal, 1=anomalía\n",
    "    df[\"anomaly\"] = df[\"anomaly\"].map({1: 0, -1: 1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc45e992-49b7-4784-876b-2641083156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_isolation_forest(df, contamination=0.1):\n",
    "    # Seleccionar solo columnas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "    X = df[numeric_cols].copy()\n",
    "\n",
    "    # Reemplazar inf y -inf por NaN\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Imputar valores NaN con la media\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=numeric_cols)\n",
    "\n",
    "    # Aplicar Isolation Forest\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_imputed)\n",
    "    df['Volumen_outlier_zscore'] = model.predict(X_imputed)  # -1 = outlier, 1 = normal\n",
    "    df['Volumen_outlier_zscore'] = df['Volumen_outlier_zscore'].map({1: 0, -1: 1})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a148062e-2e3a-40c4-a3f1-0c46055d210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a56da24-8aef-4db2-af4a-9cb7ffff64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando cliente: CLIENTE1\n",
      "Procesando cliente: CLIENTE10\n",
      "Procesando cliente: CLIENTE11\n",
      "Procesando cliente: CLIENTE12\n",
      "Procesando cliente: CLIENTE13\n",
      "Procesando cliente: CLIENTE14\n",
      "Procesando cliente: CLIENTE15\n",
      "Procesando cliente: CLIENTE16\n",
      "Procesando cliente: CLIENTE17\n",
      "Procesando cliente: CLIENTE18\n",
      "Procesando cliente: CLIENTE19\n",
      "Procesando cliente: CLIENTE2\n",
      "Procesando cliente: CLIENTE20\n",
      "Procesando cliente: CLIENTE3\n",
      "Procesando cliente: CLIENTE4\n",
      "Procesando cliente: CLIENTE5\n",
      "Procesando cliente: CLIENTE6\n",
      "Procesando cliente: CLIENTE7\n",
      "Procesando cliente: CLIENTE8\n",
      "Procesando cliente: CLIENTE9\n",
      "\n",
      "✅ Archivo 'processingdata_IF.xlsx' generado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer  # Agregado\n",
    "# Otros imports necesarios según tu función detect_with_isolation_forest\n",
    "\n",
    "# Leer archivo consolidado Excel\n",
    "df_total = pd.read_excel(\"preprocessingdata.xlsx\", engine=\"openpyxl\", parse_dates=[\"Fecha\"])\n",
    "\n",
    "# Crear lista para guardar resultados\n",
    "resultados = []\n",
    "\n",
    "# Procesar por cliente\n",
    "for cliente, df_cliente in df_total.groupby('Cliente'):\n",
    "    print(f\"Procesando cliente: {cliente}\")\n",
    "    \n",
    "    # Aplicar Isolation Forest\n",
    "    df_iforest = detect_with_isolation_forest(df_cliente)\n",
    "    \n",
    "    # Añadir columna de nombre del cliente\n",
    "    df_iforest[\"Cliente\"] = cliente\n",
    "    \n",
    "    # Guardar resultados\n",
    "    resultados.append(df_iforest)\n",
    "\n",
    "# Combinar todos los resultados en un único DataFrame\n",
    "df_resultado = pd.concat(resultados, ignore_index=True)\n",
    "\n",
    "# Guardar como archivo Excel consolidado\n",
    "df_resultado.to_excel(\"processingdata_IF.xlsx\", index=False)\n",
    "print(\"\\n✅ Archivo 'processingdata_IF.xlsx' generado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe03432-44be-4d2c-a47b-8030b2c79317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
